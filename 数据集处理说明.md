# 数据集处理流程说明

## 概述

本项目使用 **WebDataset** 格式（tar 文件）存储和处理大规模图像数据集。数据集处理流程包括数据加载、图像查找、解码、变换和批处理等步骤。

## 主要处理流程

### 1. 数据加载 (`get_cc3m_wds_dataset_and_collator`)

**文件位置**: `data/data.py`

**流程步骤**:

```python
# 1. 加载 WebDataset
data = load_dataset("webdataset", data_dir=data_args.dataset_path, split="train", streaming=True)

# 2. 数据打乱
data = data.shuffle(buffer_size=2_000, seed=data_args.seed)

# 3. 图像解码和变换
def decode(sample, img_processor):
    sample = find_image(sample)  # 查找图像字段
    sample['image'] = img_processor(sample['jpg'])  # 图像预处理
    sample['text'] = sample['txt']  # 提取文本
    return sample

data = data.map(
    partial(decode, img_processor=train_processor),
    remove_columns=['__key__', '__url__']  # 移除元数据列
)

# 4. 数据过滤
data = data.filter(lambda sample: 'image' in sample and 'text' in sample)
```

### 2. 图像查找 (`find_image`)

**功能**: 在样本中查找图像字段

**支持的文件格式**:
- `jpg`, `0.jpg`, `0.png`, `png`, `jpeg`, `0.jpeg`, `webp`

**代码**:
```python
def find_image(sample):
    for suffix in DEFAULT_IMAGE_FILE_SUFFIX:
        if suffix in sample.keys():
            sample['0.jpg'] = sample[suffix]
            break
    return sample
```

### 3. 图像变换 (`image_transform`)

**文件位置**: `data/image_data.py`, `data/transform.py`

#### 3.1 固定尺寸模式（训练/验证）

**训练模式** (`is_train=True`):
```python
transforms.Compose([
    RandomResizedCrop(image_size, scale=(0.9, 1.0), interpolation=BICUBIC),  # 随机裁剪
    _convert_to_rgb,  # 转换为RGB
    transforms.ToTensor(),  # 转为张量
    normalize,  # 归一化
])
```

**验证模式** (`is_train=False`):
```python
transforms.Compose([
    Resize(image_size, interpolation=BICUBIC),  # 调整大小
    CenterCrop(image_size),  # 中心裁剪
    _convert_to_rgb,
    transforms.ToTensor(),
    normalize,
])
```

#### 3.2 任意分辨率模式 (`image_transform_original_resolution`)

**特点**:
- 保持原始宽高比
- 调整到 patch_size 的倍数
- 最大尺寸限制为 1024 或 2048
- 返回图像张量和 patch 数量 (ph, pw)

**代码**:
```python
def image_transform_original_resolution(image, patch_size: int, max_size: int = 2048):
    w, h = map(lambda x: x // patch_size * patch_size, image.size)  # 对齐到patch大小
    
    # 限制最大尺寸
    if max(w, h) > max_size:
        if w > h:
            h = int(h / (w / max_size) // patch_size * patch_size)
            w = max_size
        else:
            w = int(w / (h / max_size) // patch_size * patch_size)
            h = max_size
    
    transform = Compose([
        CenterCrop((h, w)),  # 中心裁剪
        _convert_to_rgb,
        to_tensor,
        normalize,
    ])
    
    ph, pw = h // patch_size, w // patch_size  # 计算patch数量
    return transform(image), (ph, pw)
```

### 4. 图像归一化

**归一化参数** (OpenAI CLIP 标准):
- **均值 (Mean)**: `[0.48145466, 0.4578275, 0.40821073]`
- **标准差 (Std)**: `[0.26862954, 0.26130258, 0.27577711]`

```python
normalize = transforms.Normalize(
    mean=OPENAI_DATASET_MEAN, 
    std=OPENAI_DATASET_STD
)
```

### 5. 数据整理器 (Collator)

**文件位置**: `data/data.py`

#### 5.1 CC3M Webdataset Collator

**功能**: 
- 处理图像和文本数据
- 支持固定尺寸和任意分辨率模式

**代码**:
```python
class CC3M_WebdatasetCollator:
    def __call__(self, samples):
        images = [sample["image"] for sample in samples]
        texts = [sample["text"] for sample in samples]
        
        # 如果所有图像尺寸相同，直接stack
        if all(x is not None and x.shape == images[0].shape for x in images):
            batch['image'] = torch.stack(images)
        else:
            # 使用任意分辨率处理
            batch['image'], batch['cu_seqlens_img'], \
                batch['max_seqlen_img'], batch['grid_hw'], \
                    batch['image_sizes'] = collate_anyres(images, sizes, self.patch_size)
        
        batch['text'] = texts
        return batch
```

#### 5.2 任意分辨率批处理 (`collate_anyres`)

**功能**: 
- 处理不同尺寸的图像
- 创建 padding mask
- 生成序列长度和位置编码

**处理步骤**:
1. 计算批次中最大图像尺寸
2. 对图像进行 padding
3. 创建 padding mask
4. 将图像 reshape 为 patch 序列
5. 计算累计序列长度 (`cu_seqlens_img`)
6. 生成位置编码 (`grid_hw`)

### 6. 宽高比采样 (Aspect Ratio Sampling)

**支持的分辨率**:
- **256**: 37种宽高比 (0.25 - 4.0)
- **512**: 37种宽高比 (0.25 - 4.0)  
- **1024**: 37种宽高比 (0.25 - 4.0)

**用途**: 
在非固定尺寸模式下，从预设宽高比中随机选择进行图像变换

## 数据使用示例

### 在主脚本中的使用

```python
# run_DIVA_with_OpenAICLIP.py
from data import get_cc3m_wds_dataset_and_collator

# 获取数据集和整理器
wds_dataset, wds_collator = get_cc3m_wds_dataset_and_collator(data_args, model_args)

# 在 Trainer 中使用
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=wds_dataset,
    data_collator=wds_collator,
    optimizers=(optimizer, scheduler)
)
```

## 数据集配置参数

从 `scripts/DIVA_CLIP.sh` 可以看到关键参数:

```bash
--dataset_path datasets/cc3m/          # 数据集路径
--image_size 512                       # 图像尺寸
--fixed_image_size False               # 是否固定图像尺寸
--patch_size 16                        # Patch 大小
--dataloader_num_workers 8             # 数据加载器工作进程数
--per_device_train_batch_size 16       # 每设备批次大小
--gradient_accumulation_steps 10       # 梯度累积步数
```

## 关键特性

1. **流式加载**: 使用 `streaming=True` 支持大规模数据集
2. **数据打乱**: 使用 buffer shuffle (buffer_size=2000)
3. **多分辨率支持**: 支持固定尺寸和任意分辨率两种模式
4. **Patch 对齐**: 任意分辨率模式下自动对齐到 patch_size 的倍数
5. **批处理优化**: 智能处理不同尺寸图像的批处理

## 相关文件

- `data/data.py`: 主要数据处理函数和 Collator
- `data/image_data.py`: 图像数据处理相关函数
- `data/transform.py`: 图像变换函数
- `data/constants.py`: 常量定义（归一化参数、宽高比等）
- `run_DIVA_with_OpenAICLIP.py`: 主训练脚本
